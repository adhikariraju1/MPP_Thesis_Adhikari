summarize(population = sum(population))
View(race)
race <- spread(race, racebysex, population)
setnames(race, old =c("county.fips", "state", "year", "101", "102", "111", "112", "201",
"202", "211", "212", "301", "302", "311", "312", "401", "402", "411", "412"),
new = c("county.fips", "state", "year", "whitemale", "whitefemale", "white.his.male", "white.his.female", "blackmale",
"blackfemale", "black.his.male", "black.his.female", "indmale", "indfemale", "ind.his.male", "ind.his.female",
"asianmale", "asianfemale", "asian.his.male", "asian.his.female"))
race <- setnames(race, old =c("county.fips", "state", "year", "101", "102", "111", "112", "201",
"202", "211", "212", "301", "302", "311", "312", "401", "402", "411", "412"),
new = c("county.fips", "state", "year", "whitemale", "whitefemale", "white.his.male", "white.his.female", "blackmale",
"blackfemale", "black.his.male", "black.his.female", "indmale", "indfemale", "ind.his.male", "ind.his.female",
"asianmale", "asianfemale", "asian.his.male", "asian.his.female"))
library(data.table)
setnames(race, old =c("county.fips", "state", "year", "101", "102", "111", "112", "201",
"202", "211", "212", "301", "302", "311", "312", "401", "402", "411", "412"),
new = c("county.fips", "state", "year", "whitemale", "whitefemale", "white.his.male", "white.his.female", "blackmale",
"blackfemale", "black.his.male", "black.his.female", "indmale", "indfemale", "ind.his.male", "ind.his.female",
"asianmale", "asianfemale", "asian.his.male", "asian.his.female"))
?rename
View(race)
race <- race %>%
summarize(other.male = sum(white.his.male, black.his.male, indmale, ind.his.male, asianmale, asian.his.male))
race <- race %>%
ungroup()
summarize(other.male = sum(white.his.male, black.his.male, indmale, ind.his.male, asianmale, asian.his.male))
race <- spread(race, racebysex, population)
setnames(race, old =c("county.fips", "state", "year", "101", "102", "111", "112", "201",
"202", "211", "212", "301", "302", "311", "312", "401", "402", "411", "412"),
new = c("county.fips", "state", "year", "whitemale", "whitefemale", "white.his.male", "white.his.female", "blackmale",
"blackfemale", "black.his.male", "black.his.female", "indmale", "indfemale", "ind.his.male", "ind.his.female",
"asianmale", "asianfemale", "asian.his.male", "asian.his.female"))
race <- race %>%
group_by(county.fips, state, year, racebysex) %>%
summarize(population = sum(population))
race <- read.fwf("C:/RajuPC/MPP Final Thesis/MPP_Thesis_Adhikari/al.1990_2014.19ages.adjusted.txt",
widths = c(4,2,2,3,2,1,1,1,2,
race <- read.fwf("C:/RajuPC/MPP Final Thesis/MPP_Thesis_Adhikari/al.1990_2014.19ages.adjusted.txt",
widths = c(4,2,2,3,2,1,1,1,2,8), colClasses = "character")
library(dplyr)
library(tidyr)
library(data.table)
library(dplyr)
library(tidyr)
library(data.table)
race <- read.fwf("C:/RajuPC/MPP Final Thesis/MPP_Thesis_Adhikari/al.1990_2014.19ages.adjusted.txt",
widths = c(4,2,2,3,2,1,1,1,2,8), colClasses = "character")
colnames(race) <- c("year", "state", "state.fips", "county.fips", "registry", "race", "origin",
"sex", "age.group", "population")
race$year <- as.numeric(race$year)
race$population <- as.numeric(race$population)
race$age.group <- as.numeric(race$age.group)
#To concatenate:
race$county.fips <- paste(race$state.fips, race$county.fips, sep="")
race$county.fips <- as.numeric(race$county.fips)
race$race <- paste(race$race, race$origin, sep="")
# 10 is non-hispanic white, 20 is non-hispanic black, 30 is American indian/alaska native, 40 is Asian or Pacific
#islander, 11 is hispanic white and 21 is hispanic black.
#11 and 21 can be combined and be seen as Hispanic and 30 and 40 can be combined into Others.
race <- race[-c(3,7)] #Removing the columns from before we did the concatenate.
race <- race %>%
filter(year %% 4 == 0) %>%
filter(age.group >= 5)
#To concatenate:
#101 is white male, 201 is black male, 102 is white female, 202 is black female
#create hispanic male, hispanic female, other male, other female (301, 401 combined) (302, 402 combined)
#(111, 211 combined, and 112, 212 combined)
race$racebysex <- paste(race$race, race$sex, sep="")
race <- race[-c(5,6)]
#Now the column age group can be removed since we don't need to group by this category anymore.
race <- race[-c(5)]
race <- race[c(1,2,3,6,5)] #Subsetting into the final dataframe with only variables and in proper order.
race <- race %>%
group_by(county.fips, state, year, racebysex) %>%
summarize(population = sum(population))
race <- spread(race, racebysex, population)
setnames(race, old =c("county.fips", "state", "year", "101", "102", "111", "112", "201",
"202", "211", "212", "301", "302", "311", "312", "401", "402", "411", "412"),
new = c("county.fips", "state", "year", "whitemale", "whitefemale", "white.his.male", "white.his.female", "blackmale",
"blackfemale", "black.his.male", "black.his.female", "indmale", "indfemale", "ind.his.male", "ind.his.female",
"asianmale", "asianfemale", "asian.his.male", "asian.his.female"))
View(race)
race$other.male <- race$white.his.male + race$black.his.male + indmale + ind.his.male + asianmale + asian.his.male
race$other.male <- race$white.his.male + race$black.his.male +
race$indmale + race$ind.his.male + race$asianmale + race$asian.his.male
race$other.female <- race$white.his.female + race$black.his.female +
race$indfemale + race$ind.his.female + race$asianfemale + race$asian.his.female
race$other.female <- race$white.his.female + race$black.his.female +
race$indfemale + race$ind.his.female + race$asianfemale + race$asian.his.female
race <- race[c(1:5,8,9,20,21)]
library(xlsx)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(data.table)
library(xlsx)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(data.table)
library(xlsx)
getwd()
setwd("C:\Users\adhik\Desktop\DataFest 2017")
setwd("C:/Users/adhik/Desktop/DataFest 2017")
?fread
data <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt")
dest <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/dest.txt")
View(data)
View(dest)
View(data)
unique(data$user_location_city)
View(data)
data_us <- data %>%
filter(user_location_country=="UNITED STATES OF AMERICA")
View(data_us)
unique(data_us$user_location_city)
names(dest)
?sample
?subset
sampledata <- subset(data)
sampledata <- sample_n(data, size = 5000)
View(sampledata)
sampledata = sampledata[,c("date", "time")] := tstrsplit(date_time, split=" ")
DT = as.data.table(sampledata)
DT = DT[,c("date", "time")] := tstrsplit(date_time, split=" ")]
DT = DT[,c("date", "time")] := tstrsplit(date_time, split=" ")
DTs = DT[,c("date", "time")] := tstrsplit(date_time, split=" ")
DTs = DT[,c("date", "time") := tstrsplit(date_time, split=" ")]
View(DTs)
DT = DT[, c("year","month","day"):= tstrsplit(date, split="-")]
rm(DTs)
View(DT)
drop(DT[,date_time])
range(DT$year)
is.numeric(DT$year)
as.numeric(DT$year)
range(DT$year)
unique(DT$year)
rm(sampledata)
DT[,-"date_time"]
View(DT)
DT <- DT[,-1]
DT[, date:=NULL]
DT <- DT[,-27]
names(Data)
names(data)
unique(data$srch_destination_id)
unique(data$srch_destination_id) %>% nrow()
unique(data$srch_destination_id) %>% length()
left_join(data, dest)
left_join(fread("data.txt", stringsAsFactors = F), fread("dest.txt", stringsAsFactors = F))
left_join(fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt", stringsAsFactors = F), fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/dest.txt", stringsAsFactors = F))
data <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt")
left_join(fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt", stringsAsFactors = F), fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/dest.txt", stringsAsFactors = F))
help("memory.size")
data <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt")
setwd("C:/Users/adhik/Desktop/DataFest 2017")
data <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(data.table)
library(xlsx)
setwd("C:/Users/adhik/Desktop/DataFest 2017")
data <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/data.txt")
dest <- fread("C:/Users/adhik/Desktop/DataFest 2017/Datasets/dest.txt")
View(data)
Count(data$user_id)
length(data[,user_location_country="CANADA"])
count(data$user_location_id)
dim(data$user_location_id)
View(dest)
frequency(dest$srch_destination_type_id)
head(subset(dest, select = 'srch_destination_type_id'))
table(data$srch_destination_id)
table(data$srch_destination_id) %>% sort()
?by
?sort
t <- table(data$srch_destination_id)
barplot(t)
?table
by(t)
by.default(t)
which(t==max(t))
dest$srch_destination_name[dest$srch_destination_id==5526679]
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/RajuPC/Content Analysis/Assignment2")
library(manifestoR)
library(knitr)
library(fBasics)
library(dplyr)
mp_setapikey("manifesto_apikey.txt")
table1 <- mp_coreversions()
kable(table1, align="c", caption="All the Manifesto versions available")
df1 <- mp_maindataset(version = "current", south_america = FALSE, download_format = NULL, apikey = NULL, cache = TRUE)
df2 <- df1 %>% filter(countryname == "Germany")
df2 <- df1 %<% filter(countryname == "Germany")
df1 <- df1 %>% filter(countryname == "Germany")
df1 <- df1 %>%
filter(countryname == "Germany")
df1 <- df1 %>%
filter(countryname == "Germany")
View(df1)
df2 <- df1 %>%
filter(countryname == "Germany")
df2 <- df1 %>%
filter(countryname == "Germany")
df2 <- filter(df1$countryname == "Germany")
library("dplyr", lib.loc="~/R/win-library/3.3")
df2 <- filter(df1$countryname == "Germany")
df2 <- filter(df1$countryname == "Germany")
df2 <- df1 %>%
filter_(countryname="Germany")
df2 <- df1 %>%
filter_(countryname=="Germany")
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/RajuPC/Content Analysis/Assignment2")
library(manifestoR)
library(knitr)
library(fBasics)
library(dplyr)
mp_setapikey("manifesto_apikey.txt")
table1 <- mp_coreversions()
kable(table1, align="c", caption="All the Manifesto versions available")
df1 <- mp_maindataset(version = "current", south_america = FALSE, download_format = NULL, apikey = NULL, cache = TRUE)
table2 <- unique(df2$partyname)
df2 <- df1 %>%
filter(countryname = "Germany")
df1 <- mp_maindataset(version = "current", south_america = FALSE, download_format = NULL, apikey = NULL)
df2 <- df1 %>%
filter(countryname = "Germany")
unique(df1$countryname)
df3 <- df1 %>%
select(rile, planeco, markeco, welfare, intpeace)
df2 <- df1 %>%
filter(countryname == "Germany")
df2 <- df1 %>%
filter(countryname == "Germany")
df2 <- df1 %>%
filter(countryname == "Germany")
library(dplyr)
df2 <- df1 %>%
filter(countryname == "Germany")
View(df1)
names(df1)
df2 <- df1 %>%
filter(country = 41)
df2 <- df1 %>%
filter(country == 41)
df4 <- df1 %>%
filter(country == 41)
df2 <- df1 %>%
filter(country == 41)
df2 <- df1
df4 <- df2 %>%
filter(country == 41)
df4 <- df2 %>%
filter(df2, country == 41)
df2 <- df1 %>%
ungroup()
filter(country == 41)
df1 <- ungroup(df1)
df2 <- df1 %>%
filter(country == 41)
View(df2)
df3 <- df1 %>%
select(rile, planeco, markeco, welfare, intpeace)
table3 <- basicStats(df3)
kable(table3, align="c", caption="Summary of Descriptive Statistics", digits = 2)
df1 <- df1 %>%
ungroup() %>%
filter(countryname == "Germany")
df2 <- df1 %>%
dplyr::filter(countryname == "Germany")
table2 <- unique(df2$partyname)
kable(table2, align="c", caption="All the parties in Germany(1949-2013)", col.names ="Party Name")
df3 <- df2 %>%
select(rile, planeco, markeco, welfare, intpeace)
table3 <- basicStats(df3)
kable(table3, align="c", caption="Summary of Descriptive Statistics", digits = 2)
install.packages(c("BH", "car", "colorspace", "countrycode", "curl", "data.table", "DBI", "digest", "ggplot2", "googleVis", "jsonlite", "koRpus", "lmtest", "openssl", "openxlsx", "pbkrtest", "plm", "psych", "qdapRegex", "Rcpp", "RcppEigen", "readr", "rmarkdown", "selectr", "shiny", "sourcetools", "SparseM", "stringi", "stringr", "survival", "swirl", "tibble", "viridis", "viridisLite", "XML", "xml2", "yaml", "zoo"))
packages <- c("bea.R", "acs", "haven", "httr", "blsAPI", "rjson", "readxl", "broom", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig", "stargazer",
"lmtest", "GGally", "viridis", "ggmap", "sjPlot", "sjmisc", "ggplot2", "knitr", "tidyr", "magrittr", "plyr", "dplyr")
load <- lapply(packages, require, character.only = T)
#Setting the working directory
setwd("C:/RajuPC/MPP Final Thesis/WorkingDirectory")
#All the keys for different APIs obtained from the respective websites
blskey <- "a9e62413e38741b5aeb814efc5a3d066"
beaKey <- 'C3812F4D-F498-40F8-9F36-9FF5AF65DBD7'
censusKey <- "c7ed765d1b03f4217ccc4b37d31b0dc3580db44e"
datagovkey <- "ubFrNGonfwMQm3lK04C6djaMcqFuIe5mvev4RooI"
source("Statistics.R")
source("Statistics_Part2.R")
View(merged_df4)
rm(edu.data, emp.data, emp.data2012, emp.df, gini.data2012, gini.data2015, gini_df)
rm(p2_merged_df4, p2_merged_df5, p2_merged_df6)
descrp_p1 <- merged_df4 %>%
select(rep.share, repshare.lag, unemp_gro, Pop_thou, white.percent, rep_incumb, rural_percent)
corplot1 <- descrp_p1 %>%
select(rep.share, repshare.lag, unemp_gro) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot2 <- descrp_p1 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
print(corplot1, progress = F)
print(corplot1, progress = F)
?ggpairs
print(corplot2, progress = F)
View(descrp_p1)
plot(merged_df4$Pop_thou)
print(corplot2, progress = F)
print(corplot2, progress = F)
merged_df5 <- merged_df4 %>%
filter(Pop_thou <= 7500)
corplot99 <- merged_df5 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot99
merged_df5 <- merged_df4 %>%
filter(Pop_thou <= 100)
corplot99 <- merged_df5 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot99
merged_df5 <- merged_df4 %>%
filter(Pop_thou <= 100 & Pop_thou >= 1)
corplot99 <- merged_df5 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot99
merged_df5 <- merged_df4 %>%
filter(Pop_thou <= 75 & Pop_thou >= 0)
corplot99 <- merged_df5 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot99
View(p2_merged_df7)
View(merged_df5)
View(merged_df4)
View(descrp_p1)
View(p2_merged_df7)
#**********************************************************************************************
#Processing
#**********************************************************************************************
#Loading all the necessary packages
packages <- c("bea.R", "acs", "haven", "httr", "blsAPI", "rjson", "readxl", "broom", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig", "stargazer",
"lmtest", "GGally", "viridis", "ggmap", "sjPlot", "sjmisc", "ggplot2", "knitr", "tidyr", "magrittr", "plyr", "dplyr")
load <- lapply(packages, require, character.only = T)
#Setting the working directory
setwd("C:/RajuPC/MPP Final Thesis/WorkingDirectory")
#All the keys for different APIs obtained from the respective websites
blskey <- "a9e62413e38741b5aeb814efc5a3d066"
beaKey <- 'C3812F4D-F498-40F8-9F36-9FF5AF65DBD7'
censusKey <- "c7ed765d1b03f4217ccc4b37d31b0dc3580db44e"
datagovkey <- "ubFrNGonfwMQm3lK04C6djaMcqFuIe5mvev4RooI"
#**********************************************************************************************
source("Statistics.R")
#**********************************************************************************************
#********************************************************************************************
source("Statistics_Part2.R")
#********************************************************************************************
#************************************************************************
source("heat-map.R")
#************************************************************************
#Part I:
#Correlation Plots for Part I:
descrp_p1 <- merged_df4 %>%
select(rep.share, repshare.lag, unemp_gro, Pop_thou, white.percent, rep_incumb, rural_percent)
corplot1 <- descrp_p1 %>%
select(rep.share, repshare.lag, unemp_gro) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot2 <- descrp_p1 %>%
select(rep.share, Pop_thou, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
#We see that Los Angeles county is skewing the normal distribution of Population. So we filter it out.
merged_df5 <- merged_df4 %>%
filter(Pop_thou <= 7500)
#Regression Models:
f1 <- plm(rep.share ~ unemp_gro + repshare.lag, merged_df5, model = 'within')
f2 <- plm(rep.share ~ unemp_gro + repshare.lag + Pop_thou + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + as.factor(rural)
+ white.percent:as.factor(rural), merged_df5, model = 'within')
#Regression after Arellano-Bond:
test1 <- coeftest(f1, vcovHC(f1, method = "arellano"))
test2 <- coeftest(f2, vcovHC(f2, method = "arellano"))
#Marginal effects plots
#**************************************************************************************************************************
#For forecasting:
p2_merged_df7 <- p2_merged_df7 %>%
mutate(rep_incumb = 0)
tidy(f2)
str(fixef(f2))
intercept <- data.frame(county.fips = names(fixef(f2)),
fixef = as.vector(fixef(f2)))
p2_merged_df7 <- merge(p2_merged_df7, intercept)
p2_merged_df7 <- p2_merged_df7 %>%
mutate(pred_repshare = fixef - unemp_gro*0.0247103253 + repshare.lag*0.7276273733 + pop_thou*0.0001052426
+ white.percent*0.1558135764 - rep_incumb* 0.0404342633 - unemp_gro*rep_incumb*0.0367096008 +
white.percent*rural_percent*0.0057858007)
#png("Plot.png", width = 1800, height = 1800,
#res = 300)
p2_merged_df7 %>%
filter(!is.na(rep.share)) %>%
ggplot() +
geom_point(aes(x = pred_repshare, y = rep.share, colour = as.factor(is.rep.2012)), alpha = 0.25) +
geom_abline(slope = 1, intercept = 0) +
geom_segment(x = 0, y = 0.5, xend = 0.5, yend = 0.5, linetype = 2) +
geom_segment(x = 0.5, y = 0, xend = 0.5, yend = 0.5, linetype = 2) +
labs(x = "Predicted Republican Voteshare", y = "Actual Republican Voteshare",
title = "Residuals from 2016 US Presidential Elections Forecasting",
caption = "Source: Dave Liep, US Election Atlas") +
scale_colour_manual(values = c("steelblue", "red")) +
theme_classic() +
theme(
legend.position = "none"
)
#dev.off()
p2_merged_df8 <- p2_merged_df7 %>%
mutate(resid = rep.share - pred_repshare)
##################################################################################################################
p2_merged_df8$resid %>% abs() %>% mean(na.rm = T)
##################################################################################################################
#For correlation plot for part 2:
descrp_p2 <- p2_merged_df8 %>%
select(resid, manu_share_gro, av_wage_gro, lfpr_male_gro, gini_gro, uneduc)
corplot3 <- descrp_p2 %>%
select(rep.share, manu_share_gro, av_wage_gro, lfpr_male_gro, gini_gro, uneduc) %>%
ggpairs(lower = list("continuous" = "smooth"))
#Creating separate dataframes for swing and rust-belt states:
p2_merged_df8_swing <- p2_merged_df8 %>%
filter(state == "CO" | state == "FL" | state == "IA"
| state == "NC" | state == "NH" | state == "OH" | state == "PA"
| state == "VA" | state == "NV" | state == "WI")
p2_merged_df8_rust <- p2_merged_df8 %>%
filter(state == "NY" | state == "PA" | state == "WV" | state == "OH" | state == "IN"
| state == "MI" | state == "IL" | state == "IA" | state == "WI")
m24 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8)
#For swing states:
m25 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8_swing)
#For rust belt states:
m26 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8_rust)
#New Model with Share of Manufacturing Jobs and Average Wage and LFPR:
maps_df <- p2_merged_df8 %>%
mutate(rep.share.change = rep.share - repshare.lag)
map1 <- maps_df %>% filter(state != "HI") %>% county.heatmap("rep.share.change") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = -0.02) +
labs(title = "Change in voteshare for Republican party 2012 to 2016")
map2 <- maps_df %>% filter(state != "HI") %>% county.heatmap("flip") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.5) +
labs(title = "Counties that flipped from Democrat to Republican 2012 to 2016")
#List the counties that flipped and put it in a table (all the names) for descriptive statistics:
#flipped_counties <- descrip_df2 %>%
# filter(flip == 1)
#table(flipped_counties$state) #shows the number of counties in each state that flipped.
#Higest are: IA 33, MI 12, MN 19, NY 20, WI 23
################################# FINAL REGRESSIONS ######################################################
View(p2_merged_df7)
View(p2_merged_df8)
View(p2_merged_df8)
?sjp.int
sjp.int(f2, type = "cond")
View(merged_df5)
f1 <- plm(rep.share ~ unemp_gro + repshare.lag, merged_df5, model = 'within')
f2 <- plm(rep.share ~ unemp_gro + repshare.lag + Pop_thou + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + rural_percent
+ white.percent:rural_percent, merged_df5, model = 'within')
#Regression after Arellano-Bond:
test1 <- coeftest(f1, vcovHC(f1, method = "arellano"))
test2 <- coeftest(f2, vcovHC(f2, method = "arellano"))
sjp.int(f2, type = "cond")
sjp.int(f2, type = "cond")
sjp.int(f2, int.term = "rural_percent", type = "cond")
View(p2_merged_df8)
p2_merged_df8$resid %>% abs() %>% mean(na.rm = T)
bluetored <- p2_merged_df8 %>%
filter(is.rep.2012 = 0) %>%
filter(rep.share > 0.50) %>%
count()
bluetored <- p2_merged_df8 %>%
filter(is.rep.2012 == 0) %>%
filter(rep.share > 0.50) %>%
count()
bluetored
bluetored <- p2_merged_df8 %>%
filter(is.rep.2012 == 0) %>%
filter(rep.share > 0.50)
count(bluetored$county)
count(bluetored)
View(bluetored)
bluetoredandhigher <- bluetored %>%
filter(resid > 0)
count(bluetoredandhigher)
unique(bluetored$state)
table(bluetored$state)
table1_b2r <- table(bluetored$state)
print(table1_b2r)
table2_b2rh <- table(bluetoredandhigher$state)
table1_b2r
table2_b2rh
redtored <- p2_merged_df8 %>%
filter(is.rep.2012 == 1) %>%
filter(rep.share > 0.50)
count(redtored)
redtored <- p2_merged_df8 %>%
filter(is.rep.2012 == 1) %>%
filter(rep.share > 0.50) %>%
filter(resid > 0)
count(redtored)
table3_r2rh <- table(redtored$state)
table3_r2rh

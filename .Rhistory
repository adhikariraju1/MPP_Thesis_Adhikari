bea_df <- bea_df %>% filter(county != "NA")
bea_df$county <- tolower(bea_df$county) #Changed the county names to lowercase
#Rename the Year variable to year.
names(bea_df)[names(bea_df)=="Year"] <- "year"
bea_df <- bea_df %>%
arrange(county.fips, year) %>%
group_by(county.fips) %>%
mutate(pci_lag = lag(pci)) %>%
mutate(pop_lag = lag(pop)) %>%
mutate(pcct_lag = lag(pcct)) %>%
mutate(adj_res_lag = lag(adj_res)) %>%
filter(year %% 2 == 1)
#Calculate the one year percent change for all the economic variables from BEA
bea_df$pci_gro <- (bea_df$pci - bea_df$pci_lag)/bea_df$pci_lag
bea_df$pcct_gro <- (bea_df$pcct - bea_df$pcct_lag)/bea_df$pcct_lag
bea_df$adj_gro <- (bea_df$adj_res - bea_df$adj_res_lag)/bea_df$adj_res_lag
#subsetting only the necessary columns for the final dataframe.
bea_df2 <- bea_df[c(1:2,4:6,14:16)]
bea_df2 <- bea_df2 %>%
mutate(county = str_replace_all(county, " city", "")) %>%
mutate(county = str_replace_all(county, "doña", "dona"))
#To remove, things inside the parenthesis such as fremont (includes yellowstone park) and baltimore (independent).
bea_df2$county <-  genX(bea_df2$county, " (", ")") #qdap package helped with this.
bea_df2 <- bea_df2 %>%
ungroup() %>%
filter(state != "AK") %>%
mutate(county = ifelse(county == "maui + kalawao", "maui", county)) %>%
mutate(county.fips = ifelse(county.fips == 15901, 15009, county.fips))
#Removing all previous untidy dataframes
rm(beaPop, beaPCI, beaPercapita_Current_Transfer, beaAdjustment_Residence)
rm(Population, PerCapitaIncome, PerCapitaCurrentTransfer, AdjustmentResidence, bea_df)
#TOTO: Just saw that maui needs to have a fips code of 15009 instead of 15901 in order to merge with other datasets. I put the code above, but it didn"t work.
#TOTO: In terms of the counties in Virginia that appear with a plus sign(+), it is difficult to separate them since other variables would have to separated too and we have no means of doing that. So, what I did was that, when I did the merging at the end, I merged not by bea_df but by other dataframes. So it automatically removed the ones that had the plus sign. I guess I can say that I couldn"t incoroporate them in the model because of the complexity of the data and hence I removed them. What do you say?
#********************************************BLS unemployment datasets************************************
#BLS Data on Unemployment by county, clean data, remove unnecessary rows
unemp12 <- read_excel('laucnty12.xlsx')
unemp12 <- separate(unemp12, County, into = c("County.name", "State"), sep=",")
unemp12 <- unemp12[-c(3220:3222), ]
unemp15 <- read_excel('laucnty15.xlsx')
unemp15 <- separate(unemp15, County, into = c("County.name", "State"), sep=",")
unemp15 <- unemp15[-c(3221:3223), ]
#Combine all the dataframes from different years into one dataframe
unemployment_df <- bind_rows(unemp12, unemp15, .id = NULL)
names(unemployment_df)[names(unemployment_df)=="County.name"] <- "county"
names(unemployment_df)[names(unemployment_df)=="State"] <- "state"
names(unemployment_df)[names(unemployment_df)=="County Code"] <- "county.fips"
names(unemployment_df)[names(unemployment_df)=="State FIPS Code"] <- "state.fips"
names(unemployment_df)[names(unemployment_df)=="Year"] <- "year"
unemployment_df$county <- strsplit(unemployment_df$county, " County") #Remove the word County from the county names
unemployment_df$county <- tolower(unemployment_df$county) #Changed the county names to lowercase
unemployment_df <- unite(unemployment_df, state.fips, county.fips, col ="county.fips", sep="") #Combine two columns to make them into one.
#The states that appeared as NA in this dataframe represented DC, hence the NAs will be changed to DC
unemployment_df <- replace_na(unemployment_df, list(state="DC", unemployment_df$state))
#Converting from character to numeric for merging purposes
unemployment_df$county.fips <- as.numeric(unemployment_df$county.fips)
unemployment_df$year <- as.numeric(unemployment_df$year)
#Remove untidy dataframes from the environment
rm(unemp12, unemp15)
# There is an extra space in front or back of the state names. Need to remove them
unemployment_df <- unemployment_df %>%
mutate(state = str_replace_all(state, " ", "")) %>%
filter(state != "AK" & state != "PR")
#Rename the variable "Unemployment" to "unemp"
names(unemployment_df)[names(unemployment_df)=="Unemployment Rate"] <- "unemp"
#Do the lag of unemloyment
unemployment_df <- unemployment_df %>%
arrange(county.fips, year) %>%
group_by(county.fips) %>%
mutate(unemp_lag = lag(unemp)) %>%
filter(year %% 2 == 1)
#Calculate the one year percent change for unemployment
unemployment_df$unemp_gro <- (unemployment_df$unemp - unemployment_df$unemp_lag)/unemployment_df$unemp_lag
#subsetting only the necessary columns for the final dataframe.
unemployment_df2 <- unemployment_df[c(2:5,11)]
#Renaming certain objects in the county names
unemployment_df2 <- unemployment_df2 %>%
mutate(county = str_replace_all(county, " parish", "")) %>%
mutate(county = str_replace_all(county, " city", "")) %>%
mutate(county = str_replace_all(county, " town", ""))
#Removing untidy dataframes:
rm(unemployment_df)
beabls_df <- merge(unemployment_df2, bea_df2, by= c('county.fips'), all.x = TRUE) #Merging first two datasets
beablselec <- merge(beabls_df, election_df, by =c('county.fips'), all.x = TRUE)
View(beablselec)
merged_df1 <- beablselec[c(1:3,5,9:12,16:19)] #Subsetting into the final dataframe with only variables and in proper order.
names(merged_df1)[names(merged_df1)=="county.x"] <- "county"
names(merged_df1)[names(merged_df1)=="state.x"] <- "state"
View(merged_df1)
#Remove untidy dataframes:
rm(beabls_df, beablselec, election_df, unemployment_df2, bea_df2)
#Rural dummy:
rural <- read.csv("rural.csv")
rural <- rural[c(1,4,5)]
names(rural)[names(rural)=="ï..county.fips"] <- "county.fips"
p2_merged_df <- merge(merged_df1, rural, by = 'county.fips', all.x = TRUE)
View(p2_merged_df)
# White dummy
race <- read.csv("race2015.csv")
race <- race[-c(1:3)]
names(race)[names(race)=="FIPS"] <- "county.fips"
p2_merged_df2 <- merge(p2_merged_df, race, by = c('county.fips'), all.x = TRUE)
p2_merged_df2$white.percent <- p2_merged_df2$white / p2_merged_df2$pop
#Removing duplicate counties. There were 6 of them.
issue.data <- p2_merged_df2 %>%
group_by(county.fips) %>%
summarise(issue = n())
p2_merged_df2 %<>% merge(issue.data) %>%
mutate(drop = ifelse(issue > 6 & is.na(pop), 1, 0)) %>%
filter(drop == 0) %>%
select(-drop, -issue)
rm(issue.data, merged_df1, pe_merged_df, race, rural)
rm(issue.data, merged_df1, pe_merged_df, race, rural, p2_merged_df)
View(p2_merged_df2)
p2_merged_df2$rep.share.gro = p2_merged_df2$rep.share - p2_merged_df2$repshare.lag
p2_merged_df3 <- p2_merged_df2[-c("black","white","other")]
p2_merged_df3 <- p2_merged_df2[-c(15:17)]
View(p2_merged_df3)
p2_merged_df4 <- p2_merged_df3
View(p2_merged_df4)
source("Statistics_Part2.R")
View(p2_merged_df4)
p2_m1_ols <- lm(rep.share.gro ~ unemp_gro + pci_gro, p2_merged_df4)
summary(p2_m1_ols)
p2_m2_ols <- lm(rep.share.gro ~ unemp_gro + pci_gro + white.percent + as.factor(rural) +
white.percent:as.factor(rural), p2_merged_df4)
summary(p2_m2_ols)
p2_m2_ols <- lm(rep.share.gro ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), p2_merged_df4)
summary(p2_m2_ols)
logit.data <- p2_merged_df4 %>%
mutate(flip = is.rep.2016 - is.rep.2012) %>%
filter(flip != -1)
?lm
p2_m2_logit <- glm(rep.share.gro ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), logit.data, family = binomial(link = "logit"))
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), logit.data, family = binomial(link = "logit"))
summary(p2_m2_logit)
table(logit.data$flip)
table(logit.data$flip) %>% sum()
223 / table(logit.data$flip) %>% sum()
logit.data <- p2_merged_df4 %>%
mutate(flip = is.rep.2016 - is.rep.2012)
table(logit.data$flip)
223 / table(logit.data$flip) %>% sum()
install.packages("Zelig")
packages <- c("bea.R", "acs", "magrittr", "httr", "tidyr", "blsAPI", "rjson", "readxl", "dplyr", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig")
load <- lapply(packages, require, character.only = T)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), model = "relogit", logit.data)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), model = "relogit", data = logit.data)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural), model = "relogit", data = logit.data, tau = 0.1)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent,
model = "relogit", data = logit.data, tau = 0.1)
?zelig
logit.data <- p2_merged_df4 %>%
mutate(flip = is.rep.2016 - is.rep.2012) %>%
filter(flip != -1)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent,
model = "relogit", data = logit.data)
summary(p2_m2_relogit)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent,
model = "relogit", data = logit.data, tau = c(0.5, 0.1))
summary(p2_m2_relogit)
?setx
t <- set.x(p2_m2_relogit)
t <- setx(p2_m2_relogit)
str(t)
summary(t)
t <- setx(p2_m2_relogit) %>% sim(p2_m2_relogit, .)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent,
model = "relogit", data = logit.data, tau = 0.5)
summary(p2_m2_relogit)
p2_m2_relogit <- zelig(flip ~ unemp_gro + pci_gro + pop + white.percent,
model = "relogit", data = logit.data, tau = 0.05)
summary(p2_m2_relogit)
summary(p2_m2_logit)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1)
head(edu.data)
View(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"))
View(edu.data)
colnames(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`)
colnames(edu.data)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "")
View(edu.data)
colnames(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "")
View(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
View(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade"))
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
View(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2"))
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
View(edu.data)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2"))
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
rename(county.fips = id2)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
dplyr::rename(county.fips = id2)
?dplyr::rename
data("iris")
colnames(iris)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
dplyr::rename(county.fips = Id2)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
View(edu.data)
rm(iris)
colnames(edu.data)
?rowsum
edu.data %<>%
select(-Professionalschooldegree, -Regularhighschooldiploma, -`12thgradenodiploma`) %>%
mutate(total = rowsum(.) - county.fips)
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
dplyr::rename(county.fips = Id2)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
edu.data %<>%
select(-Professionalschooldegree, -Regularhighschooldiploma, -`12thgradenodiploma`) %>%
mutate(total = rowSums(.) - county.fips)
View(edu.data)
581 + 93 + 17 + 12 + 256 + 107 + 328 + 696 + 858 + 1067
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
dplyr::rename(county.fips = Id2)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
edu.data %<>%
select(-Professionalschooldegree, -Regularhighschooldiploma, -`12thgradenodiploma`) %>%
mutate(total = rowSums(.) - county.fips) %>%
select(county.fips, total)
View(edu.data)
p2_merged_df4 <- merge(p2_merged_df3, edu.data)
View(p2_merged_df4)
p2_m1_ols <- lm(rep.share.gro ~ unemp_gro + pci_gro + total, p2_merged_df4)
summary(p2_m1_ols)
logit.data <- p2_merged_df4 %>%
mutate(flip = is.rep.2016 - is.rep.2012) %>%
filter(flip != -1)
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural) + total, logit.data, family = binomial(link = "logit"))
summary(p2_m2_logit)
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:as.factor(rural) + total:as.factor(rural), logit.data, family = binomial(link = "logit"))
summary(p2_m2_logit)
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + white.percent + as.factor(rural) +
white.percent:total, logit.data, family = binomial(link = "logit"))
summary(p2_m2_logit)
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop +total, logit.data, family = binomial(link = "logit"))
summary(p2_m2_logit)
county.heatmap <- function(data, variable, fips = "FIPS",
shape_file = "ShapeFile.xlsx",
colour = "A") {
# Checking for packages and stopping if not installed
pkgs <- c('ggplot2', 'ggmap', 'dplyr', 'viridis', 'rio')
loaded <- sapply(pkgs, require, character.only = T)
if (any(loaded == F)) {
pkgs_needed <- pkgs[!loaded]
pkgs_message <- paste(pkgs_needed, collapse = "\n ")
stop(paste("There is an error! The following packages are needed; \n",
pkgs_message))
}
# Checking the shapefile
if (is.character(shape_file)) {
us.shp <- try(rio::import(shape_file))
if (inherits(us.shp, "try-error")) stop("Shapefile not found!")
} else if (is.data.frame(shape_file)){
us.shp <- shape_file
} else {
stop("ShapeFile is Missing!! Please see your inputs")
}
# Merging to get the correct dataset
temp.plot <- data %>%
mutate_(FIPS = fips) %>%
left_join(us.shp) %>%
ggplot(aes(x = long, y = lat, group = group)) +
geom_polygon(aes_string(fill = variable), colour = "white", size = 0.1) +
scale_fill_viridis(option = colour) +
theme_nothing()
return(temp.plot)
}
county.heatmap <- function(data, variable, fips = "county.fips",
shape_file = "ShapeFile.xlsx",
colour = "A") {
# Checking for packages and stopping if not installed
pkgs <- c('ggplot2', 'ggmap', 'dplyr', 'viridis', 'rio')
loaded <- sapply(pkgs, require, character.only = T)
if (any(loaded == F)) {
pkgs_needed <- pkgs[!loaded]
pkgs_message <- paste(pkgs_needed, collapse = "\n ")
stop(paste("There is an error! The following packages are needed; \n",
pkgs_message))
}
# Checking the shapefile
if (is.character(shape_file)) {
us.shp <- try(rio::import(shape_file))
if (inherits(us.shp, "try-error")) stop("Shapefile not found!")
} else if (is.data.frame(shape_file)){
us.shp <- shape_file
} else {
stop("ShapeFile is Missing!! Please see your inputs")
}
# Merging to get the correct dataset
temp.plot <- data %>%
mutate_(FIPS = fips) %>%
left_join(us.shp) %>%
ggplot(aes(x = long, y = lat, group = group)) +
geom_polygon(aes_string(fill = variable), colour = "white", size = 0.1) +
scale_fill_viridis(option = colour) +
theme_nothing()
return(temp.plot)
}
View(p2_merged_df4)
p2_merged_df4 %>% county.heatmap(rep.share)
county.heatmap(p2_merged_df4, rep.share)
county.heatmap(p2_merged_df4, "rep.share")
table(p2_merged_df4$state)
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share")
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + theme(legend.position = "left")
county.heatmap <- function(data, variable, fips = "county.fips",
shape_file = "ShapeFile.xlsx",
colour = "A") {
# Checking for packages and stopping if not installed
pkgs <- c('ggplot2', 'ggmap', 'dplyr', 'viridis', 'rio')
loaded <- sapply(pkgs, require, character.only = T)
if (any(loaded == F)) {
pkgs_needed <- pkgs[!loaded]
pkgs_message <- paste(pkgs_needed, collapse = "\n ")
stop(paste("There is an error! The following packages are needed; \n",
pkgs_message))
}
# Checking the shapefile
if (is.character(shape_file)) {
us.shp <- try(rio::import(shape_file))
if (inherits(us.shp, "try-error")) stop("Shapefile not found!")
} else if (is.data.frame(shape_file)){
us.shp <- shape_file
} else {
stop("ShapeFile is Missing!! Please see your inputs")
}
# Merging to get the correct dataset
temp.plot <- data %>%
mutate_(FIPS = fips) %>%
left_join(us.shp) %>%
ggplot(aes(x = long, y = lat, group = group)) +
geom_polygon(aes_string(fill = variable), colour = "white", size = 0.1) +
scale_fill_viridis(option = colour) +
theme_minimal()
return(temp.plot)
}
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share")
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient(low = "blue", high = "red")
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "blue", high = "red", mid = "steelblue")
?scale_fill_gradient2
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "blue", high = "red", mid = "steelblue", midpoint = 0.5)
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "steelblue", high = "red", mid = "grey", midpoint = 0.5)
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.5)
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.45)
p2_merged_df4 %>% filter(state != "HI") %>% county.heatmap("rep.share") + scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.40)
View(logit.data)
source("Statistics.R")
View(merged_df4)
View(election_df2)
race <- read.csv("race1992_2012.csv")
View(race)
race <- race[-c(1:2)]
names(race)[names(race)=="FIPS"] <- "county.fips"
merged_df4 <- merge(merged_df3, race, by = c('county.fips', 'year'), all.x = TRUE)
merged_df4$white.percent <- merged_df4$white / merged_df4$Pop
View(p2_merged_df4)
#********************************************Pre-processing ritual************************************
#Loading all the necessary packages
packages <- c("bea.R", "acs", "magrittr", "httr", "tidyr", "blsAPI", "rjson", "readxl", "dplyr", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig")
load <- lapply(packages, require, character.only = T)
#Setting the working directory
setwd("C:/RajuPC/MPP Final Thesis/WorkingDirectory")
#All the keys for different APIs obtained from the respective websites
blskey <- "a9e62413e38741b5aeb814efc5a3d066"
beaKey <- 'C3812F4D-F498-40F8-9F36-9FF5AF65DBD7'
censusKey <- "c7ed765d1b03f4217ccc4b37d31b0dc3580db44e"
datagovkey <- "ubFrNGonfwMQm3lK04C6djaMcqFuIe5mvev4RooI"
source("Statistics.R")
#********************************************Pre-processing ritual************************************
#Loading all the necessary packages
packages <- c("bea.R", "acs", "magrittr", "httr", "tidyr", "blsAPI", "rjson", "readxl", "dplyr", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig")
load <- lapply(packages, require, character.only = T)
#Setting the working directory
setwd("C:/RajuPC/MPP Final Thesis/WorkingDirectory")
#All the keys for different APIs obtained from the respective websites
blskey <- "a9e62413e38741b5aeb814efc5a3d066"
beaKey <- 'C3812F4D-F498-40F8-9F36-9FF5AF65DBD7'
censusKey <- "c7ed765d1b03f4217ccc4b37d31b0dc3580db44e"
datagovkey <- "ubFrNGonfwMQm3lK04C6djaMcqFuIe5mvev4RooI"
source("Statistics.R")
packages <- c("bea.R", "acs", "magrittr", "httr", "tidyr", "blsAPI", "rjson", "readxl", "dplyr", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "Zelig", "stargazer")
load <- lapply(packages, require, character.only = T)
p1_m1_ols <- lm(rep.share ~ unemp_gro + PCI_gro + repshare.lag, merged_df4)
p1_m1_fe <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag, merged_df4, model = 'within')
p1_m1_re <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag, merged_df4, model = 'random')
phtest(p1_m1_fe, p1_m1_re) #H
stargazer::stargazer(p1_m1_ols, p1_m1_fe, p1_m1_re, digits = 2, header = FALSE,
title = 'Base Model (OLS, FE, RE)', font.size = 'normalsize')
stargazer::stargazer(p1_m1_ols, p1_m1_fe, p1_m1_re, type = 'html', digits = 2, header = FALSE,
title = 'Base Model (OLS, FE, RE)', font.size = 'normalsize')
stargazer::stargazer(p1_m1_ols, p1_m1_fe, p1_m1_re, type = 'text', digits = 2, header = FALSE,
title = 'Base Model (OLS, FE, RE)', font.size = 'normalsize')
p1_m2_fe <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag + Pop + white.percent + rep_incumbent
, merged_df4, model = 'within')
View(merged_df4)
p1_m2_fe <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag + Pop + white.percent + rep_incumb
, merged_df4, model = 'within')
stargazer::stargazer(p1_m2_fe, type = 'text', digits = 2, header = FALSE,
title = 'Model with Controls (FE)', font.size = 'normalsize')
p1_m2_fe <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag + Pop + white.percent + as.factor(rep_incumb)
, merged_df4, model = 'within')
stargazer::stargazer(p1_m2_fe, type = 'text', digits = 2, header = FALSE,
title = 'Model with Controls (FE)', font.size = 'normalsize')
p1_m3_fe <- plm(rep.share ~ unemp_gro + PCI_gro + repshare.lag + Pop + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + PCI_gro:as.factor(rep_incumb) + as.factor(rural)
+ white.percent:as.factor(rural), merged_df4, model = 'within')
stargazer::stargazer(p1_m3_fe, type = 'text', digits = 2, header = FALSE,
title = 'Model with Controls and Interactions (FE)', font.size = 'normalsize')
source("Statistics_Part2.R")
p2_m1_logit <- glm(flip ~ unemp_gro + pci_gro, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m1_logit, type = 'text', digits = 2, header = FALSE,
title = 'Base Model Logit', font.size = 'normalsize')
View(logit.data)
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + total + white.percent +
rural, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m2_logit, type = 'text', digits = 2, header = FALSE,
title = 'Base Model Logit', font.size = 'normalsize')
p2_m3_logit <- glm(flip ~ unemp_gro + pci_gro + pop + total + white.percent + total:white.percent +
white.percent:rural + rural, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m3_logit, type = 'text', digits = 2, header = FALSE,
title = 'Base Model Logit', font.size = 'normalsize')
source("heat-map.R")
logit.data %>% filter(state != "HI") %>% county.heatmap("unemp_gro") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.40)
logit.data %>% filter(state != "HI") %>% county.heatmap("unemp_gro") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0)
logit.data %>% filter(state != "HI") %>% county.heatmap("total") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.49)
logit.data$educ = logit.data$total / logit.data$pop
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + educ + white.percent +
rural, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m2_logit, type = 'text', digits = 2, header = FALSE,
title = 'With Controls Model Logit', font.size = 'normalsize')
p2_m2_logit <- glm(flip ~ unemp_gro + pci_gro + pop + educ + white.percent +
rural, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m2_logit, type = 'text', digits = 2, header = FALSE,
title = 'With Controls Model Logit', font.size = 'normalsize')
p2_m3_logit <- glm(flip ~ unemp_gro + pci_gro + pop + educ + white.percent + educ:white.percent +
white.percent:rural + rural, logit.data, family = binomial(link = "logit"))
stargazer::stargazer(p2_m3_logit, type = 'text', digits = 2, header = FALSE,
title = 'With Interactions Model Logit', font.size = 'normalsize')

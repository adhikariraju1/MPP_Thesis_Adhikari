'GeoFips' = 'COUNTY' ,
'ResultFormat' = 'json'
);
beaPrivate <- beaGet(beaPrivate, asString = T, asTable = F)
Private <- jsonlite::fromJSON(beaPrivate)$BEAAPI$Results$Data %>%
mutate(DataValue = ifelse(DataValue == '(NA)', NA, DataValue),
DataValue = as.numeric(DataValue)) %>%
rename(Year = TimePeriod, private = DataValue) %>%
mutate(Year = as.numeric(Year))
Private <- Private %>%
select(GeoFips, GeoName, Year, private)
#BEA Regional Income Data: Employment(Total number of jobs) by county
beaEMP <- list(
'UserID' = beaKey ,
'Method' = 'GetData',
'datasetname' = 'RegionalIncome',
'TableName' = 'CA30' ,
'LineCode' = '240',
'Year' = '2014, 2015' ,
'GeoFips' = 'COUNTY' ,
'ResultFormat' = 'json'
);
beaEMP <- beaGet(beaEMP, asString = T, asTable = F)
Jobs <- jsonlite::fromJSON(beaEMP)$BEAAPI$Results$Data %>%
mutate(DataValue = ifelse(DataValue == '(NA)', NA, DataValue),
DataValue = as.numeric(DataValue)) %>%
rename(Year = TimePeriod, jobs = DataValue) %>%
mutate(Year = as.numeric(Year))
Jobs <- Jobs %>%
select(GeoFips, GeoName, Year, jobs)
#Average wage by county
beaWage <- list(
'UserID' = beaKey ,
'Method' = 'GetData',
'datasetname' = 'RegionalIncome',
'TableName' = 'CA30' ,
'LineCode' = '290',
'Year' = '2014, 2015' ,
'GeoFips' = 'COUNTY' ,
'ResultFormat' = 'json'
);
beaWage <- beaGet(beaWage, asString = T, asTable = F)
Wage <- jsonlite::fromJSON(beaWage)$BEAAPI$Results$Data %>%
mutate(DataValue = ifelse(DataValue == '(NA)', NA, DataValue),
DataValue = as.numeric(DataValue)) %>%
rename(Year = TimePeriod, av_wage = DataValue) %>%
mutate(Year = as.numeric(Year))
Wage <- Wage %>%
select(GeoFips, GeoName, Year, av_wage)
#Merging all BEA dataframes
bea_df <- merge(Population, PerCapitaIncome, by = c('GeoFips', 'Year', 'GeoName'), all=T)
bea_df <- merge(bea_df, PerCapitaCurrentTransfer, by = c('GeoFips', 'Year', 'GeoName'), all=T)
bea_df <- merge(bea_df, Jobs, by = c('GeoFips', 'Year', 'GeoName'), all=T)
bea_df <- merge(bea_df, Wage, by = c('GeoFips', 'Year', 'GeoName'), all=T)
bea_df <- merge(bea_df, Manufacturing, by = c('GeoFips', 'Year', 'GeoName'), all=T)
bea_df <- merge(bea_df, Private, by = c('GeoFips', 'Year', 'GeoName'), all=T)
names(bea_df)[names(bea_df)=="GeoFips"] <- "county.fips"
bea_df$county.fips <- as.numeric(bea_df$county.fips)
## Custom function
geo_seperate <- function(text, digit = 1) {
# This function is to use the text in the column GeoName and seperate them into two parts; the one with the state and the one with counties. Then use dplyr to mutate the columns respectivly
temp.text <- str_split(text, ", ") %>% unlist() %>%
# Split at the comma. and force the text to take between 1:3 parts
str_replace_all("[*]", "")
if (length(temp.text) == 3) {
# Correcting the state and county names if more than one comma in their names
temp.text <- c(paste(temp.text[1:2], collapse = ", "), temp.text[3])
}
if (length(temp.text) == 1) {
return(NA) # For those with only US or state names
} else {
return(temp.text[digit])
}
}
bea_df %<>%
rowwise() %>%
mutate(county = geo_seperate(GeoName, 1),
state = geo_seperate(GeoName, 2)) %>%
select(county.fips, Year, GeoName, state, county, everything())
# Only need to filter out the NAs from state and county now
bea_df <- bea_df %>%
filter(county != "NA")
bea_df$county <- tolower(bea_df$county) #Changed the county names to lowercase
#Rename the Year variable to year.
bea_df <- bea_df %>%
rename(year = Year, pop = Pop, pci = PCI, pcct = PCCT)
bea_df <- bea_df %>%
arrange(county.fips, year) %>%
group_by(county.fips) %>%
mutate(pci_lag = lag(pci)) %>%
mutate(pop_lag = lag(pop)) %>%
mutate(pcct_lag = lag(pcct)) %>%
mutate(jobs_lag = lag(jobs)) %>%
mutate(av_wage_lag = lag(av_wage)) %>%
mutate(manu_share = manu / private) %>%
mutate(manu_share_lag = lag(manu_share)) %>%
filter(year %% 2 == 1)
#Calculate the one year percent change for all the economic variables from BEA
bea_df <- bea_df %>%
mutate(pci_gro = (pci - pci_lag) / pci_lag,
pcct_gro = (pcct - pcct_lag) /pcct_lag,
jobs_gro = (jobs - jobs_lag) / jobs_lag,
av_wage_gro = (av_wage - av_wage_lag) / av_wage_lag,
manu_share_gro = (manu_share - manu_share_lag) / manu_share_lag)
#subsetting only the necessary columns for the final dataframe.
bea_df <- bea_df %>%
mutate(pop_thou = pop / 1000) %>%
select(county.fips, year, state, county, pop, pop_thou, pci_gro, pcct_gro, jobs_gro, av_wage_gro, manu_share_gro)
bea_df <- bea_df %>%
mutate(county = str_replace_all(county, " city", "")) %>%
mutate(county = str_replace_all(county, "doÃ±a", "dona"))
#To remove, things inside the parenthesis such as fremont (includes yellowstone park) and baltimore (independent).
bea_df$county <-  genX(bea_df$county, " (", ")") #qdap package helped with this.
bea_df <- bea_df %>%
ungroup() %>%
filter(state != "AK") %>%
mutate(county = ifelse(county == "maui + kalawao", "maui", county)) %>%
mutate(county.fips = ifelse(county.fips == 15901, 15009, county.fips))
#********************************************BLS unemployment datasets************************************
#BLS Data on Unemployment by county, clean data, remove unnecessary rows
unemp14 <- read_excel('laucnty14.xlsx')
unemp14 <- separate(unemp14, County, into = c("County.name", "State"), sep=",")
unemp15 <- read_excel('laucnty15.xlsx')
unemp15 <- separate(unemp15, County, into = c("County.name", "State"), sep=",")
#Combine all the dataframes from different years into one dataframe
unemployment_df <- bind_rows(unemp14, unemp15, .id = NULL)
unemployment_df <- unemployment_df %>%
rename(county = County.name, state = State,
county.fips = `County Code`,
state.fips = `State FIPS Code`,
year = Year,
unemp = `Unemployment Rate`)
unemployment_df$county <- strsplit(unemployment_df$county, " County") #Remove the word County from the county names
unemployment_df$county <- tolower(unemployment_df$county) #Changed the county names to lowercase
unemployment_df <- unite(unemployment_df, state.fips, county.fips, col ="county.fips", sep="") #Combine two columns to make them into one.
#The states that appeared as NA in this dataframe represented DC, hence the NAs will be changed to DC
unemployment_df <- replace_na(unemployment_df, list(state="DC", unemployment_df$state))
#Converting from character to numeric for merging purposes
unemployment_df$county.fips <- as.numeric(unemployment_df$county.fips)
unemployment_df$year <- as.numeric(unemployment_df$year)
# There is an extra space in front or back of the state names. Need to remove them
unemployment_df <- unemployment_df %>%
mutate(state = str_replace_all(state, " ", "")) %>%
filter(state != "AK" & state != "PR")
#Do the lag of unemloyment
unemployment_df <- unemployment_df %>%
arrange(county.fips, year) %>%
group_by(county.fips) %>%
mutate(unemp_lag = lag(unemp)) %>%
filter(year %% 2 == 1)
#Calculate the one year percent change for unemployment
unemployment_df <- unemployment_df %>%
mutate(unemp_gro = (unemp - unemp_lag) / unemp_lag) %>%
select(county.fips, county, state, year, unemp_gro)
#Renaming certain objects in the county names
unemployment_df <- unemployment_df %>%
mutate(county = str_replace_all(county, " parish", "")) %>%
mutate(county = str_replace_all(county, " city", "")) %>%
mutate(county = str_replace_all(county, " town", ""))
beabls_df <- merge(unemployment_df, bea_df, by= c('county.fips'), all.x = TRUE) #Merging first two datasets
beablselec <- merge(beabls_df, election_df, by =c('county.fips'), all.x = TRUE)
p2_merged_df1 <- beablselec %>%
select(county.fips, county.x, state.x, unemp_gro, pop, pop_thou, pci_gro, pcct_gro,
jobs_gro, av_wage_gro, manu_share_gro, rep.share, repshare.lag, is.rep.2012, is.rep.2016) %>%
rename(county = county.x, state = state.x)
#Rural dummy:
rural <- read.csv("rural.csv")
rural <- rural %>%
rename(county.fips = ï..county.fips) %>%
select(county.fips, rural_percent, rural)
p2_merged_df2 <- merge(p2_merged_df1, rural, by = 'county.fips', all.x = TRUE)
# White dummy 18 years and above white
race <- read.csv("race2015.csv")
race <- race %>%
rename(county.fips = FIPS) %>%
select(county.fips, white)
p2_merged_df3 <- merge(p2_merged_df2, race, by = c('county.fips'), all.x = TRUE)
p2_merged_df3 <- p2_merged_df3 %>%
mutate(white.percent = white / pop)
issue.data <- p2_merged_df3 %>%
group_by(county.fips) %>%
summarise(issue = n())
p2_merged_df3 %<>% merge(issue.data) %>%
mutate(drop = ifelse(issue > 1 & is.na(pop), 1, 0)) %>%
filter(drop == 0) %>%
select(-drop, -issue)
## Load and clean the education data:
edu.data <- rio::import("ACS_15_5YR_B15003_with_ann.csv", skip = 1) %>%
select(-matches("Margin"), -`Estimate; Total:`) %>%
select(matches("school|Kinder|grade|id2")) %>%
dplyr::rename(county.fips = Id2)
colnames(edu.data) <- colnames(edu.data) %>%
stringi::stri_replace_all_fixed("Estimate; Total: - ", "") %>%
stringi::stri_replace_all_fixed(" ", "") %>%
stringi::stri_replace_all_regex(",|'", "")
edu.data %<>%
select(-Professionalschooldegree, -Regularhighschooldiploma, -`12thgradenodiploma`) %>%
mutate(total = rowSums(.) - county.fips) %>%
select(county.fips, total)
p2_merged_df4 <- merge(p2_merged_df3, edu.data)
p2_merged_df4 <- p2_merged_df4 %>%
mutate(uneduc = total / pop)
p2_merged_df5 <- p2_merged_df4 %>%
mutate(flip = is.rep.2016 - is.rep.2012)
p2_merged_df5 <- p2_merged_df5 %>%
mutate(rep.share.gro = (rep.share - repshare.lag)/repshare.lag)
emp.data <- rio::import("ACS_15_5YR_S2301_with_ann.csv", skip = 1) %>%
select(-matches("Margin")) %>%
select(-matches("Total")) %>%
select(-matches("Unemployment")) %>%
select(-matches("Female")) %>%
select(-matches("AGE")) %>%
select(-matches("DISABILITY")) %>%
select(-matches("Employment")) %>%
select(-matches("RACE")) %>%
select(-matches("EDUCATIONAL")) %>%
select(-matches("POVERTY")) %>%
select(-Id, -Geography)
names(emp.data)[names(emp.data)=="Labor Force Participation Rate; Estimate; White alone, not Hispanic or Latino"] <- "lfpr_white_2015"
names(emp.data)[names(emp.data)=="Labor Force Participation Rate; Estimate; Population 20 to 64 years - SEX - Male"] <- "lfpr_male_2015"
names(emp.data)[names(emp.data)=="Id2"] <- "county.fips"
emp.data <- emp.data %>%
select(county.fips, lfpr_male_2015, lfpr_white_2015)
emp.data2014 <- rio::import("ACS_14_5YR_S2301_with_ann,csv", skip = 1) %>%
select(-matches("Margin")) %>%
select(-matches("Total")) %>%
select(-matches("Unemployment")) %>%
select(-matches("Female")) %>%
select(-matches("AGE")) %>%
select(-matches("DISABILITY")) %>%
select(-matches("Employment")) %>%
select(-matches("RACE")) %>%
select(-matches("EDUCATIONAL")) %>%
select(-matches("POVERTY")) %>%
select(-matches("Employed")) %>%
select(-Id, -Geography)
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; White alone, not Hispanic or Latino"] <- "lfpr_white_2014"
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; SEX - Male"] <- "lfpr_male_2014"
names(emp.data2014)[names(emp.data2014)=="Id2"] <- "county.fips"
emp.data2014 <- rio::import("ACS_14_5YR_S2301_with_ann.csv", skip = 1) %>%
select(-matches("Margin")) %>%
select(-matches("Total")) %>%
select(-matches("Unemployment")) %>%
select(-matches("Female")) %>%
select(-matches("AGE")) %>%
select(-matches("DISABILITY")) %>%
select(-matches("Employment")) %>%
select(-matches("RACE")) %>%
select(-matches("EDUCATIONAL")) %>%
select(-matches("POVERTY")) %>%
select(-matches("Employed")) %>%
select(-Id, -Geography)
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; White alone, not Hispanic or Latino"] <- "lfpr_white_2014"
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; SEX - Male"] <- "lfpr_male_2014"
names(emp.data2014)[names(emp.data2014)=="Id2"] <- "county.fips"
emp.data2014 <- emp.data2014 %>%
select(county.fips, lfpr_male_2014, lfpr_white_2014)
emp.data2014 <- rio::import("ACS_14_5YR_S2301_with_ann.csv", skip = 1) %>%
select(-matches("Margin")) %>%
select(-matches("Total")) %>%
select(-matches("Unemployment")) %>%
select(-matches("Female")) %>%
select(-matches("AGE")) %>%
select(-matches("DISABILITY")) %>%
select(-matches("Employment")) %>%
select(-matches("RACE")) %>%
select(-matches("EDUCATIONAL")) %>%
select(-matches("POVERTY")) %>%
select(-matches("Employed")) %>%
select(-Id, -Geography)
View(emp.data2014)
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; White alone, not Hispanic or Latino"] <- "lfpr_white_2014"
names(emp.data2014)[names(emp.data2014)=="In labor force; Estimate; Population 20 to 64 years - SEX - Male"] <- "lfpr_male_2014"
names(emp.data2014)[names(emp.data2014)=="Id2"] <- "county.fips"
emp.data2014 <- emp.data2014 %>%
select(county.fips, lfpr_male_2014, lfpr_white_2014)
emp.df <- merge(emp.data, emp.data2014)
p2_merged_df6 <- p2_merged_df6 %>%
mutate(lfpr_male_gro = lfpr_male_2015 - lfpr_male_2014) %>%
mutate(lfpr_white_gro = lfpr_white_2015 - lfpr_white_2014)
p2_merged_df6 <- merge(p2_merged_df5, emp.df, all.x = TRUE)
p2_merged_df6 <- p2_merged_df6 %>%
mutate(lfpr_male_gro = lfpr_male_2015 - lfpr_male_2014) %>%
mutate(lfpr_white_gro = lfpr_white_2015 - lfpr_white_2014)
gini.data2015 <- rio::import("ACS_15_5YR_B19083_with_ann.csv", skip = 1)
names(gini.data2015)[names(gini.data2015)=="Estimate; Gini Index"] <- "gini_2015"
names(gini.data2015)[names(gini.data2015)=="Id2"] <- "county.fips"
gini.data2015 <- gini.data2015 %>%
select(county.fips, gini_2015)
gini.data2014 <- rio::import("ACS_14_5YR_B19083_with_ann.csv", skip = 1)
names(gini.data2014)[names(gini.data2014)=="Estimate; Gini Index"] <- "gini_2014"
names(gini.data2014)[names(gini.data2014)=="Id2"] <- "county.fips"
gini.data2014 <- gini.data2014 %>%
select(county.fips, gini_2014)
gini_df <- merge(gini.data2015, gini.data2014)
gini_df <- gini_df %>%
mutate(gini_gro = gini_2015 - gini_2014)
p2_merged_df7 <- merge(p2_merged_df6, gini_df, all.x = TRUE)
anal_2014 <- p2_merged_df7
export(anal_2014, "2014anal.csv")
anal_df <- rio::import("2014anal.csv", skip = 1)
View(anal_df)
View(anal_2014)
View(anal_df)
anal_df <- rio::import("2014anal.csv")
View(anal_df)
anal_df <- anal_df %>%
mutate(rep_incumb = 0)
anal_df <- merge(anal_df, intercept)
#**********************************************************************************************
#Processing
#**********************************************************************************************
#Loading all the necessary packages
packages <- c("bea.R", "acs", "haven", "httr", "blsAPI", "rjson", "readxl", "broom", "jsonlite",
"stringr", "rJava", "xlsx", "qdap", "data.table", "plm", "rio", "stargazer",
"lmtest", "GGally", "viridis", "ggmap", "sjPlot", "sjmisc", "ggplot2", "knitr", "tidyr",
"magrittr", "plyr", "dplyr", "gridExtra", "grid")
load <- lapply(packages, require, character.only = T)
#Setting the working directory
setwd("C:/RajuPC/MPP Final Thesis/WorkingDirectory")
#All the keys for different APIs obtained from the respective websites
blskey <- "a9e62413e38741b5aeb814efc5a3d066"
beaKey <- 'C3812F4D-F498-40F8-9F36-9FF5AF65DBD7'
censusKey <- "c7ed765d1b03f4217ccc4b37d31b0dc3580db44e"
datagovkey <- "ubFrNGonfwMQm3lK04C6djaMcqFuIe5mvev4RooI"
source("Statistics.R")
source("Statistics_Part2.R")
source("heat-map.R")
#Part I:
#Correlation Plots for Part I:
descrp_p1 <- merged_df4 %>%
select(rep.share, repshare.lag, unemp_gro, log.Pop, white.percent, rep_incumb, rural_percent)
corplot1 <- descrp_p1 %>%
select(rep.share, repshare.lag, unemp_gro) %>%
ggpairs(lower = list("continuous" = "smooth"))
corplot2 <- descrp_p1 %>%
select(rep.share, log.Pop, white.percent, rural_percent) %>%
ggpairs(lower = list("continuous" = "smooth"))
merged_df5 <- merged_df4
#Regression Models:
f1 <- plm(rep.share ~ unemp_gro + repshare.lag, merged_df5, model = 'within')
f2 <- plm(rep.share ~ unemp_gro + repshare.lag + log(Pop) + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + rural_percent
+ white.percent:rural_percent, merged_df5, model = 'within')
f3 <- plm(rep.share ~ unemp_gro + repshare.lag + log(Pop) + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + rural_percent
+ white.percent:rural_percent + year, merged_df5, model = 'within')
f2random <- plm(rep.share ~ unemp_gro + repshare.lag + log(Pop) + white.percent + as.factor(rep_incumb)
+ unemp_gro:as.factor(rep_incumb) + rural_percent
+ white.percent:rural_percent, merged_df5, model = 'random')
#Regression after Arellano-Bond:
test1 <- coeftest(f1, vcovHC(f1, method = "arellano"))
test2 <- coeftest(f2, vcovHC(f2, method = "arellano"))
test3 <- coeftest(f3, vcovHC(f3, method = "arellano"))
#Marginal effects plots
#Can"t be done.
#**************************************************************************************************************************
#For forecasting:
p2_merged_df7 <- p2_merged_df7 %>%
mutate(rep_incumb = 0)
tidy(f3)
str(fixef(f3))
intercept <- data.frame(county.fips = names(fixef(f3)),
fixef = as.vector(fixef(f3)))
p2_merged_df7 <- merge(p2_merged_df7, intercept)
p2_merged_df7 <- p2_merged_df7 %>%
mutate(pred_repshare = fixef - unemp_gro*0.010424064 + repshare.lag*0.667388497 + log(pop)*0.013094576
+ white.percent*0.438572256 - rep_incumb* 0.091746860 - unemp_gro*rep_incumb*0.003444465 -
white.percent*rural_percent*0.003856760)
#png("Plot.png", width = 1800, height = 1800,
#res = 300)
p2_merged_df7 %>%
filter(!is.na(rep.share)) %>%
ggplot() +
geom_point(aes(x = pred_repshare, y = rep.share, colour = as.factor(is.rep.2012)), alpha = 0.25) +
geom_abline(slope = 1, intercept = 0) +
geom_segment(x = 0, y = 0.5, xend = 0.5, yend = 0.5, linetype = 2) +
geom_segment(x = 0.5, y = 0, xend = 0.5, yend = 0.5, linetype = 2) +
labs(x = "Predicted Republican Voteshare", y = "Actual Republican Voteshare") +
scale_colour_manual(values = c("steelblue", "red")) +
theme_classic() +
theme(
legend.position = "none"
)
#dev.off()
p2_merged_df8 <- p2_merged_df7 %>%
mutate(resid = rep.share - pred_repshare)
##################################################################################################################
#Table in forecasting section:
p2_merged_df8$resid %>% abs() %>% mean(na.rm = T)
###################################################################
bluetored <- p2_merged_df8 %>%
filter(is.rep.2012 == 0) %>%
filter(rep.share > 0.50)
table1_b2r <- table(bluetored$state) %>%
as.data.frame() %>%
rename(State = Var1, `Counties D to R` = Freq)
bluetoredandhigher <- bluetored %>%
filter(resid > 0)
table1_b2rh <- table(bluetoredandhigher$state) %>%
as.data.frame() %>%
rename(State = Var1, `Counties Underpredicted` = Freq)
table100 <- merge(table1_b2r, table1_b2rh, all = TRUE)
#
redtored <- p2_merged_df8 %>%
filter(is.rep.2012 == 1) %>%
filter(rep.share > 0.50)
table1_r2r <- table(redtored$state) %>%
as.data.frame() %>%
rename(State = Var1, `Counties R to R` = Freq)
redtoredhigher <- redtored %>%
filter(resid > 0)
table1_r2rh <- table(redtoredhigher$state) %>%
as.data.frame() %>%
rename(State = Var1, `Counties underpredicted` = Freq)
table200 <- merge(table1_r2r, table1_r2rh, all =TRUE)
##################################################################################################################
#For correlation plot for part 2:
descrp_p2 <- p2_merged_df8 %>%
select(resid, manu_share_gro, av_wage_gro, lfpr_male_gro, gini_gro, uneduc)
corplot3 <- descrp_p2 %>%
select(resid, manu_share_gro, av_wage_gro, lfpr_male_gro, gini_gro, uneduc) %>%
ggpairs(lower = list("continuous" = "smooth"))
#Creating separate dataframes for swing and rust-belt states:
p2_merged_df8_swing <- p2_merged_df8 %>%
filter(state == "CO" | state == "FL" | state == "IA"
| state == "NC" | state == "NH" | state == "OH" | state == "PA"
| state == "VA" | state == "NV" | state == "WI")
p2_merged_df8_rust <- p2_merged_df8 %>%
filter(state == "NY" | state == "PA" | state == "WV" | state == "OH" | state == "IN"
| state == "MI" | state == "IL" | state == "IA" | state == "WI")
#New Model with Share of Manufacturing Jobs and Average Wage and LFPR:
maps_df <- p2_merged_df8 %>%
mutate(rep.share.change = rep.share - repshare.lag)
map_theme <-   theme(
legend.position = "none",
panel.grid = element_blank(),
axis.title = element_blank(),
axis.text = element_blank()
)
map1 <- maps_df %>% filter(state != "HI") %>% county.heatmap("rep.share.change") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = -0.02) +
map_theme
map2 <- maps_df %>% filter(state != "HI") %>% county.heatmap("flip") +
scale_fill_gradient2(low = "#085BB2", high = "#FF2312", mid = "#4DAFFF", midpoint = 0.5) +
map_theme
map3 <- maps_df %>% filter(state != "HI") %>% county.heatmap("resid") +
scale_fill_viridis(option = "A", discrete = FALSE) +
map_theme
map4 <- maps_df %>% filter(state != "HI") %>% county.heatmap("rep.share.change") +
scale_fill_viridis(option = "A", discrete = FALSE) +
map_theme
#List the counties that flipped and put it in a table (all the names) for descriptive statistics:
#flipped_counties <- descrip_df2 %>%
# filter(flip == 1)
#table(flipped_counties$state) #shows the number of counties in each state that flipped.
#Higest are: IA 33, MI 12, MN 19, NY 20, WI 23
m24 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8)
#For swing states:
m25 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8_swing)
#For rust belt states:
m26 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, p2_merged_df8_rust)
anal_df <- rio::import("2014anal.csv")
anal_df <- anal_df %>%
mutate(rep_incumb = 0)
anal_df <- merge(anal_df, intercept)
anal_df <- anal_df %>%
mutate(pred_repshare = fixef - unemp_gro*0.010424064 + repshare.lag*0.667388497 + log(pop)*0.013094576
+ white.percent*0.438572256 - rep_incumb* 0.091746860 - unemp_gro*rep_incumb*0.003444465 -
white.percent*rural_percent*0.003856760)
anal_df1 <- anal_df %>%
mutate(resid = rep.share - pred_repshare)
anal_swing <- anal_df1 %>%
filter(state == "CO" | state == "FL" | state == "IA"
| state == "NC" | state == "NH" | state == "OH" | state == "PA"
| state == "VA" | state == "NV" | state == "WI")
anal_rust <- anal_df1 %>%
filter(state == "NY" | state == "PA" | state == "WV" | state == "OH" | state == "IN"
| state == "MI" | state == "IL" | state == "IA" | state == "WI")
m100 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, anal_df1)
m101 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, anal_swing)
m102 <- lm(resid ~ -1 + manu_share_gro + av_wage_gro + lfpr_male_gro + gini_gro + uneduc, anal_rust)
swingtable <- table(anal_swing$state)
swingtable <- table(p2_merged_df8_swing$state)
rusttable <- table(p2_merged_df8_rust$state)
swingtable <- table(p2_merged_df8_swing$state) %>%
as.data.frame() %>%
rename(State = Var1, `Number of counties` = Freq)
rusttable <- table(p2_merged_df8_rust$state) %>%
as.data.frame() %>%
rename(State = Var1, `Number of counties` = Freq)
trial.df <- maps_df %>% select(resid, rep.share.change) %>% mutate(t = resid / rep.share.change, t =  round(t, 3))
table(trial.df$t)
table(abs(trial.df$t))
table(round(abs(trial.df$t), 2))
View(maps_df)
map3 <- maps_df %>% filter(state != "HI") %>% county.heatmap("resid") +
scale_fill_viridis(option = "A", discrete = FALSE, direction = -1) +
map_theme
map3
map4 <- maps_df %>% filter(state != "HI") %>% county.heatmap("rep.share.change") +
scale_fill_viridis(option = "A", discrete = FALSE) +
labs(caption="Lighter shade implies higher Republican vote share in 2016") +
map_theme
map4
map3 <- maps_df %>% filter(state != "HI") %>% county.heatmap("resid") +
scale_fill_viridis(option = "A", discrete = FALSE, direction = -1) +
labs(caption="Darker shade implies higher residual") +
map_theme
map3
map4
count(redtoredhigher)
